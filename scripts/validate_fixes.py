#!/usr/bin/env python3
"""
validate_fixes.py - Validation script for critical fixes.

Tests that:
1. w_cost is properly extracted and affects features in rl_adapter.py
2. MAE encoder produces diverse embeddings
3. Configuration values are correct (ent_coef, sde_sample_freq)
"""

import sys
import os
from pathlib import Path

# Add project root to path
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, ROOT_DIR)

import torch
import numpy as np
from gymnasium import spaces

from src.models.rl_adapter import FoundationFeatureExtractor
from src.config import TQCTrainingConfig, WFOTrainingConfig


def test_w_cost_affects_features():
    """Test that w_cost properly affects feature extraction."""
    print("\n" + "="*70)
    print("TEST 1: w_cost affects features")
    print("="*70)
    
    # Create observation space
    obs_space = spaces.Dict({
        "market": spaces.Box(
            low=-np.inf,
            high=np.inf,
            shape=(64, 43),
            dtype=np.float32
        ),
        "position": spaces.Box(
            low=-1.0,
            high=1.0,
            shape=(1,),
            dtype=np.float32
        ),
        "w_cost": spaces.Box(
            low=0.0,
            high=1.0,
            shape=(1,),
            dtype=np.float32
        )
    })
    
    # Create extractor (will warn if weights not found, but that's OK for this test)
    encoder_path = "weights/wfo/segment_0/encoder.pth"
    if not os.path.exists(encoder_path):
        encoder_path = "weights/pretrained_encoder.pth"
    
    try:
        extractor = FoundationFeatureExtractor(
            obs_space,
            encoder_path=encoder_path,
            freeze_encoder=True
        )
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not load encoder: {e}")
        print("   Using random weights for test (features will still differ)")
        extractor = FoundationFeatureExtractor(
            obs_space,
            encoder_path="nonexistent.pth",  # Will use random weights
            freeze_encoder=False
        )
    
    # Test with different w_cost values
    batch_size = 4
    obs1 = {
        "market": torch.randn(batch_size, 64, 43),
        "position": torch.zeros(batch_size, 1),
        "w_cost": torch.zeros(batch_size, 1)  # w_cost = 0
    }
    obs2 = {
        "market": obs1["market"].clone(),  # Same market data
        "position": obs1["position"].clone(),  # Same position
        "w_cost": torch.ones(batch_size, 1)  # w_cost = 1 (different!)
    }
    
    with torch.no_grad():
        feat1 = extractor(obs1)
        feat2 = extractor(obs2)
    
    # Check if features differ
    diff = (feat1 - feat2).norm().item()
    are_different = not torch.allclose(feat1, feat2, atol=1e-6)
    
    print(f"  w_cost=0 features shape: {feat1.shape}")
    print(f"  w_cost=1 features shape: {feat2.shape}")
    print(f"  L2 difference: {diff:.6f}")
    print(f"  Features differ: {are_different}")
    
    if are_different:
        print("  ‚úÖ PASS: w_cost affects features correctly")
        return True
    else:
        print("  ‚ùå FAIL: w_cost does NOT affect features (should differ!)")
        return False


def test_mae_produces_diverse_features():
    """Test that MAE encoder produces diverse embeddings for different inputs."""
    print("\n" + "="*70)
    print("TEST 2: MAE produces diverse embeddings")
    print("="*70)
    
    obs_space = spaces.Dict({
        "market": spaces.Box(low=-np.inf, high=np.inf, shape=(64, 43), dtype=np.float32),
        "position": spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32),
        "w_cost": spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32)
    })
    
    encoder_path = "weights/wfo/segment_0/encoder.pth"
    if not os.path.exists(encoder_path):
        encoder_path = "weights/pretrained_encoder.pth"
    
    try:
        extractor = FoundationFeatureExtractor(
            obs_space,
            encoder_path=encoder_path,
            freeze_encoder=True
        )
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not load encoder: {e}")
        print("   Using random weights for test")
        extractor = FoundationFeatureExtractor(
            obs_space,
            encoder_path="nonexistent.pth",
            freeze_encoder=False
        )
    
    # Test with different market data
    batch_size = 4
    obs_a = {
        "market": torch.randn(batch_size, 64, 43),
        "position": torch.zeros(batch_size, 1),
        "w_cost": torch.zeros(batch_size, 1)
    }
    obs_b = {
        "market": torch.randn(batch_size, 64, 43),  # Different market data
        "position": torch.zeros(batch_size, 1),
        "w_cost": torch.zeros(batch_size, 1)
    }
    
    with torch.no_grad():
        feat_a = extractor(obs_a)
        feat_b = extractor(obs_b)
    
    diff = (feat_a - feat_b).norm().item()
    are_different = diff > 0.1  # Should be significantly different
    
    print(f"  Market A features shape: {feat_a.shape}")
    print(f"  Market B features shape: {feat_b.shape}")
    print(f"  L2 difference: {diff:.6f}")
    print(f"  Features are diverse: {are_different}")
    
    if are_different:
        print("  ‚úÖ PASS: MAE produces diverse features correctly")
        return True
    else:
        print("  ‚ö†Ô∏è  WARNING: Features are very similar (might be OK if encoder is frozen and inputs are similar)")
        return True  # Not a critical failure


def test_config_values():
    """Test that configuration values are correct."""
    print("\n" + "="*70)
    print("TEST 3: Configuration values")
    print("="*70)
    
    # Test TQCTrainingConfig
    tqc_config = TQCTrainingConfig()
    print(f"\n  TQCTrainingConfig:")
    print(f"    ent_coef: {tqc_config.ent_coef}")
    print(f"    sde_sample_freq: {tqc_config.sde_sample_freq}")
    
    tqc_ok = (
        tqc_config.ent_coef == "auto_0.1" and
        tqc_config.sde_sample_freq == 64
    )
    
    if tqc_ok:
        print("    ‚úÖ PASS: TQCTrainingConfig values are correct")
    else:
        print("    ‚ùå FAIL: TQCTrainingConfig values are incorrect!")
        print(f"      Expected: ent_coef='auto_0.1', sde_sample_freq=64")
        print(f"      Got: ent_coef={tqc_config.ent_coef}, sde_sample_freq={tqc_config.sde_sample_freq}")
    
    # Test WFOTrainingConfig
    wfo_config = WFOTrainingConfig()
    print(f"\n  WFOTrainingConfig:")
    print(f"    ent_coef: {wfo_config.ent_coef}")
    print(f"    sde_sample_freq: {wfo_config.sde_sample_freq}")
    
    wfo_ok = (
        wfo_config.ent_coef == "auto_0.1" and
        wfo_config.sde_sample_freq == 64
    )
    
    if wfo_ok:
        print("    ‚úÖ PASS: WFOTrainingConfig values are correct")
    else:
        print("    ‚ùå FAIL: WFOTrainingConfig values are incorrect!")
        print(f"      Expected: ent_coef='auto_0.1', sde_sample_freq=64")
        print(f"      Got: ent_coef={wfo_config.ent_coef}, sde_sample_freq={wfo_config.sde_sample_freq}")
    
    return tqc_ok and wfo_ok


def test_rl_adapter_forward_signature():
    """Test that rl_adapter.forward() accepts w_cost."""
    print("\n" + "="*70)
    print("TEST 4: rl_adapter.forward() signature")
    print("="*70)
    
    import inspect
    from src.models.rl_adapter import FoundationFeatureExtractor
    
    # Get forward method signature
    sig = inspect.signature(FoundationFeatureExtractor.forward)
    print(f"  forward() signature: {sig}")
    
    # Check docstring mentions w_cost
    doc = FoundationFeatureExtractor.forward.__doc__
    has_w_cost_in_doc = "w_cost" in doc if doc else False
    
    print(f"  Docstring mentions w_cost: {has_w_cost_in_doc}")
    
    # Try to call forward with w_cost
    obs_space = spaces.Dict({
        "market": spaces.Box(low=-np.inf, high=np.inf, shape=(64, 43), dtype=np.float32),
        "position": spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32),
        "w_cost": spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32)
    })
    
    try:
        extractor = FoundationFeatureExtractor(
            obs_space,
            encoder_path="nonexistent.pth",  # Will use random weights
            freeze_encoder=False
        )
        
        # Test forward call
        obs = {
            "market": torch.randn(2, 64, 43),
            "position": torch.zeros(2, 1),
            "w_cost": torch.ones(2, 1)
        }
        
        with torch.no_grad():
            features = extractor(obs)
        
        print(f"  forward() accepts w_cost: ‚úÖ")
        print(f"  Output shape: {features.shape}")
        return True
        
    except KeyError as e:
        if "w_cost" in str(e):
            print(f"  ‚ùå FAIL: forward() does not accept w_cost!")
            return False
        raise
    except Exception as e:
        print(f"  ‚ö†Ô∏è  Error during forward test: {e}")
        return False


def main():
    """Run all validation tests."""
    print("\n" + "="*70)
    print("VALIDATION DES CORRECTIONS CRITIQUES")
    print("="*70)
    
    results = []
    
    # Test 1: w_cost affects features
    results.append(("w_cost affects features", test_w_cost_affects_features()))
    
    # Test 2: MAE produces diverse features
    results.append(("MAE produces diverse features", test_mae_produces_diverse_features()))
    
    # Test 3: Configuration values
    results.append(("Configuration values", test_config_values()))
    
    # Test 4: forward() signature
    results.append(("forward() signature", test_rl_adapter_forward_signature()))
    
    # Summary
    print("\n" + "="*70)
    print("R√âSUM√â")
    print("="*70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status}: {test_name}")
    
    print(f"\n  Total: {passed}/{total} tests passed")
    
    if passed == total:
        print("\n  üéâ TOUS LES TESTS SONT PASS√âS!")
        return 0
    else:
        print(f"\n  ‚ö†Ô∏è  {total - passed} test(s) ont √©chou√©")
        return 1


if __name__ == "__main__":
    sys.exit(main())
