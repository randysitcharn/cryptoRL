# AmÃ©liorations Futures - CryptoRL

Liste des amÃ©liorations prÃ©vues pour le projet, priorisÃ©es par importance.

---

## P0 - Haute PrioritÃ©

### [x] Short Selling Support âœ… IMPLÃ‰MENTÃ‰

**Fichier:** `src/training/batch_env.py` (lignes 681-684)

**Statut:** âœ… **IMPLÃ‰MENTÃ‰** (2026-01-19)

**ImplÃ©mentation actuelle:**
```python
# Direct mapping: -1=100% short, 0=cash, +1=100% long
target_exposures = target_positions
target_values = old_navs * target_exposures
target_units = target_values / old_prices
```

**FonctionnalitÃ©s:**
- âœ… Mapping symÃ©trique : action=-1 = -100% short, action=0 = cash, action=1 = +100% long
- âœ… Calcul NAV supporte positions nÃ©gatives (`cash + positions * prices`)
- âœ… Action space `[-1, 1]` et position space `[-1, 1]`
- âœ… Funding rate pour positions short (voir P1 ci-dessous)

**Impact:** L'agent peut profiter des marchÃ©s baissiers.

---

### [ ] Curriculum Lambda Max Tuning
**Fichier:** `src/training/batch_env.py` (ligne 843)

**ProblÃ¨me actuel:**
```python
# Phase 3: Stability - fixed discipline
self.curriculum_lambda = 0.4
```
Le lambda max est hardcodÃ© Ã  0.4.

**Solution proposÃ©e:**
- Rendre configurable via paramÃ¨tre `curriculum_lambda_max: float = 0.4`
- ExpÃ©rimenter avec valeurs 0.3, 0.5, 0.6 pour trouver l'optimum
- Logger la valeur dans TensorBoard pour analyse

**Impact:** Permet de tuner le ratio PnL/Penalties selon les rÃ©sultats OOS.

---

## P1 - Moyenne PrioritÃ©

### [x] Funding Rate pour Shorts âœ… IMPLÃ‰MENTÃ‰

**Fichier:** `src/training/batch_env.py` (lignes 702-706)

**Statut:** âœ… **IMPLÃ‰MENTÃ‰** (2026-01-19)

**ImplÃ©mentation actuelle:**
```python
# 6b. Apply funding cost for short positions (perpetual futures style)
if self.funding_rate > 0:
    short_mask = self.positions < 0
    funding_cost = torch.abs(self.positions) * old_prices * self.funding_rate
    self.cash = torch.where(short_mask, self.cash - funding_cost, self.cash)
```

**FonctionnalitÃ©s:**
- âœ… ParamÃ¨tre `funding_rate: float = 0.0001` (0.01% par step, ~0.24%/jour)
- âœ… AppliquÃ© uniquement sur positions nÃ©gatives (`positions < 0`)
- âœ… DÃ©duit du cash Ã  chaque step
- âœ… Configurable via constructeur de `BatchCryptoEnv`

**Impact:** Short selling rÃ©aliste avec coÃ»t de funding style perpetual futures.

---

### [ ] Smooth Coef Tuning
**Fichier:** `src/training/callbacks.py` (ligne 597)

**ProblÃ¨me actuel:**
```python
{'end_progress': 0.3, 'churn': (0.10, 0.50), 'smooth': (0.0, 0.005)},
```
`smooth_coef` rÃ©duit Ã  0.005 pour "unblock trading".

**Solution proposÃ©e:**
- Monitorer le nombre de trades par Ã©pisode
- Si < 10 trades/Ã©pisode, c'est OK
- Si agent ne trade jamais, augmenter progressivement (0.01, 0.02)

**Impact:** Balance entre rÃ©duction du churn et capacitÃ© Ã  trader.

---

### [x] Data Augmentation - Dynamic Noise (Annealing + Volatility-Adaptive)

**Fichier:** `src/training/batch_env.py`

**Statut:** âœ… **IMPLÃ‰MENTÃ‰** (2026-01-19) - Voir `docs/AUDIT_OBSERVATION_NOISE.md`

**ProblÃ¨me actuel:**
```python
noise = torch.randn_like(market) * self.observation_noise  # Bruit fixe Ã  1%
```
Le bruit est constant quelle que soit la volatilitÃ© du marchÃ© et la progression du training.

**Solution approuvÃ©e (combinÃ©e):**
```python
if self.observation_noise > 0 and self.training:
    # 1. ANNEALING (Time-based) - Standard NoisyRollout 2025
    annealing_factor = 1.0 - 0.5 * self.progress
    
    # 2. ADAPTIVE (Regime-based) - Innovation CryptoRL
    current_vol = torch.sqrt(self.ema_vars).clamp(min=1e-6)
    target_vol = getattr(self, 'target_volatility', 0.015)
    vol_factor = (target_vol / current_vol).clamp(0.5, 2.0)  # CRITIQUE: garde-fous
    
    # 3. INJECTION COMBINÃ‰E
    final_scale = self.observation_noise * annealing_factor * vol_factor
    noise = torch.randn_like(market) * final_scale.unsqueeze(1).unsqueeze(2)
    market = market + noise
```

**Intuition:** 
- Annealing: Exploration forte au dÃ©but, prÃ©cision Ã  la fin (standard industriel)
- Volatility-Adaptive: Plus de bruit en marchÃ© calme, moins en marchÃ© volatile

**Impact:** Meilleure gÃ©nÃ©ralisation, convergence plus stable.

---

## P2 - Basse PrioritÃ©

### [x] ~~Observation Noise Adaptive~~ (FusionnÃ© dans P1)

**Statut:** âœ… **FUSIONNÃ‰** dans "Dynamic Noise" (P1) - Voir audit 2026-01-19

L'annealing fait maintenant partie de la solution combinÃ©e approuvÃ©e.

---

### [x] WFO In-Train Evaluation âœ… IMPLÃ‰MENTÃ‰

**Fichier:** `scripts/run_full_wfo.py`

**Statut:** âœ… **IMPLÃ‰MENTÃ‰** (2026-01-19)

**Description:**
Ajoute un split "eval" entre train et test pour permettre l'Ã©valuation in-train (EvalCallback) pendant le WFO.

**SchÃ©ma:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â—„â”€â”€â”€â”€â”€â”€ 14 mois â”€â”€â”€â”€â”€â”€â–ºâ—„â”€ 1m â”€â–ºâ—„â”€â”€â”€â”€â”€â”€ 3 mois â”€â”€â”€â”€â”€â”€â–º                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚       TRAIN         â”‚â”‚ EVAL â”‚â”‚     TEST (OOS)      â”‚                â”‚
â”‚  â”‚   (apprentissage)   â”‚â”‚(in-  â”‚â”‚  (validation WFO)   â”‚                â”‚
â”‚  â”‚                     â”‚â”‚train)â”‚â”‚                     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration:**
```python
# WFOConfig (scripts/run_full_wfo.py)
train_months: int = 14       # Training data (excluding eval)
eval_months: int = 1         # In-train evaluation
test_months: int = 3         # Out-of-sample test
```

**Usage CLI:**
```bash
# DÃ©faut: 14m train / 1m eval / 3m test
python scripts/run_full_wfo.py

# PersonnalisÃ©: 12m train / 2m eval / 3m test  
python scripts/run_full_wfo.py --train-months 12 --eval-months 2
```

**Avantages:**
- Early stopping intelligent via EvalCallback
- Best model selection basÃ© sur eval (pas train)
- Signal 3 OverfittingGuard (train/eval divergence) fonctionne
- Pas de data leakage (test reste invisible)

**Impact:** DÃ©tection prÃ©coce de l'overfitting, meilleure sÃ©lection de modÃ¨le.

---

### [ ] Multi-Asset Support
**Fichier:** `src/training/batch_env.py`

**Description:**
Ã‰tendre BatchCryptoEnv pour gÃ©rer un portefeuille multi-assets (BTC + ETH).

**Solution proposÃ©e:**
- Action space: `Box(-1, 1, shape=(n_assets,))`
- Positions indÃ©pendantes par asset
- Contrainte: somme des expositions <= max_leverage

**Impact:** Permet la diversification et les stratÃ©gies de spread.

---

### [ ] Data Augmentation - Magnitude Scaling

**Fichier:** `src/training/batch_env.py`

**Description:**
Multiplier les observations par un facteur alÃ©atoire pour simuler diffÃ©rentes conditions de volatilitÃ©.

**Solution proposÃ©e:**
```python
if self.training and self.magnitude_scaling:
    scale = torch.empty(n_envs, 1, 1, device=self.device).uniform_(0.9, 1.1)
    market = market * scale
```

**Intuition:** Un mouvement de +5% et un mouvement de +5.5% sont essentiellement le mÃªme signal.

**Impact:** Simule diffÃ©rentes conditions de volatilitÃ©, prÃ©serve la structure relative des donnÃ©es.

---

### [ ] Data Augmentation - Time Warping

**Fichier:** `src/training/batch_env.py`

**Description:**
Ã‰tirer/compresser temporellement certaines portions de la sÃ©rie temporelle.

**Intuition:** Un rallye de 3 jours et un de 5 jours peuvent Ãªtre le mÃªme pattern, juste Ã  vitesse diffÃ©rente.

**Attention:** Complexe Ã  implÃ©menter. Peut casser les relations temporelles importantes (ex: momentum sur 24h).

**Impact:** CrÃ©e de la variÃ©tÃ© structurelle pour les patterns de chartisme.

---

## P3 - Futur

### [ ] Data Augmentation - Synthetic Episode Generation

**Fichier:** Nouveau module Ã  crÃ©er

**Description:**
GÃ©nÃ©rer des Ã©pisodes synthÃ©tiques avec des modÃ¨les gÃ©nÃ©ratifs (GANs, Diffusion Models) entraÃ®nÃ©s sur les donnÃ©es historiques.

**Impact:** Haute valeur si bien fait, mais effort trÃ¨s Ã©levÃ©. Ã€ considÃ©rer uniquement si les autres techniques sont insuffisantes.

---

### [ ] HMM Relative Artifacts + A/B Testing
**Fichier:** `src/data_engineering/features.py`

**ProblÃ¨me actuel:**
Les artifacts HMM sont fixes (probabilitÃ©s de rÃ©gime absolues).

**Solution proposÃ©e:**
- Passer Ã  des artifacts relatifs (ex: changement de probabilitÃ©, distance au centroÃ¯de du rÃ©gime, temps passÃ© dans le rÃ©gime actuel)
- ImplÃ©menter un framework A/B testing pour comparer les performances agent avec vs sans features HMM
- MÃ©triques Ã  comparer : Sharpe OOS, max drawdown, stabilitÃ© des performances

**Impact:** Valider objectivement l'apport du HMM et potentiellement amÃ©liorer la qualitÃ© des features de rÃ©gime.

---

### [ ] 3 HMM Timeframes
**Fichier:** `src/data_engineering/features.py`

**Description:**
EntraÃ®ner plusieurs HMM sur diffÃ©rents timeframes pour capturer les rÃ©gimes Ã  plusieurs Ã©chelles temporelles.

**Solution proposÃ©e:**
- Ã€ dÃ©finir (multi-timeframe, hiÃ©rarchique, ou ensemble)

**Impact:** Potentiellement capturer des rÃ©gimes de marchÃ© Ã  court, moyen et long terme.

---

### [x] A/B Testing: gSDE vs Actor Noise âœ… IMPLÃ‰MENTÃ‰

**Fichier:** `src/training/train_agent.py`, `src/config/training.py`

**Statut:** âœ… **IMPLÃ‰MENTÃ‰** (2026-01-19)

**Description:**
Support pour deux approches d'exploration pour TQC:
1. **gSDE (generalized State-Dependent Exploration):** Bruit dans l'espace des paramÃ¨tres, corrÃ©lÃ© au state (dÃ©faut)
2. **Actor Noise (OrnsteinUhlenbeckActionNoise):** Bruit sur les actions, indÃ©pendant du state

**Configuration:**
```python
# Config A: gSDE (dÃ©faut)
use_sde: bool = True

# Config B: Actor Noise
use_sde: bool = False
use_action_noise: bool = True      # Active OU noise quand gSDE off
action_noise_sigma: float = 0.1    # Ã‰cart-type du bruit (0.05-0.3)
action_noise_theta: float = 0.15   # Taux de retour Ã  la moyenne
```

**Usage CLI:**
```bash
# DÃ©faut: gSDE activÃ©
python -m src.training.train_agent

# Alternative: OrnsteinUhlenbeck noise
python -m src.training.train_agent --no-sde --action-noise-sigma 0.1 --action-noise-theta 0.15
```

**MÃ©triques Ã  comparer (A/B testing):**
- Sharpe OOS (Walk-Forward)
- Max Drawdown
- StabilitÃ© inter-folds
- Convergence speed (timesteps to plateau)
- Action smoothness (churn)

**Impact:** Permet de tester quelle stratÃ©gie d'exploration fonctionne mieux pour le trading RL.

---

## Propositions REJETÃ‰ES (Audit 2026-01-19)

Les propositions suivantes ont Ã©tÃ© Ã©valuÃ©es et rejetÃ©es lors de l'audit. Voir `docs/AUDIT_OBSERVATION_NOISE.md` pour les justifications complÃ¨tes.

### [x] ~~Feature-Specific Noise~~ ğŸ”´ REJETÃ‰

**Raison:** ComplexitÃ© de maintenance trop Ã©levÃ©e pour gain marginal.

**DÃ©tails:**
- Mapping features â†’ groupes fragile et difficile Ã  maintenir
- Valeurs (0.5%, 2%, 1%, 0%) purement heuristiques sans validation
- Couplage fort avec pipeline de features
- ROI insuffisant : +5% estimÃ© vs. effort permanent

**Alternative:** Reporter aprÃ¨s validation des techniques approuvÃ©es (Dynamic Noise).

---

### [x] ~~SNI (Selective Noise Injection)~~ ğŸ”´ REJETÃ‰

**Raison:** Changement architectural trop profond, hors scope.

**DÃ©tails:**
- NÃ©cessite modification du forward pass ou architecture dual-path
- Impact sur toute la chaÃ®ne d'entraÃ®nement (TQC, callbacks)
- Paper original (NeurIPS 2024) testÃ© sur CoinRun, pas finance
- Risque de rÃ©gression Ã©levÃ©
- Effort : 1+ jour vs. quelques heures pour solutions approuvÃ©es

**Alternative:** CrÃ©er ticket de recherche pour Ã©valuation future.

---

## Data Augmentation - Techniques Ã  Ã‰VITER

| Technique | Pourquoi l'Ã©viter |
|-----------|-------------------|
| **Flip temporel** | Le temps a une direction. Un pattern inversÃ© temporellement devient complÃ¨tement diffÃ©rent. |
| **Shuffling des features** | Les colonnes ont une sÃ©mantique fixe. Le modÃ¨le apprend que colonne 0 = prix. |
| **Mixup/CutMix** | MÃ©langer deux contextes de marchÃ© crÃ©e une chimÃ¨re irrÃ©aliste (mi-bull mi-bear). |
| **Bruit trop fort (>5%)** | DÃ©truit le signal. Le modÃ¨le apprend Ã  ignorer les observations. |

---

## Notes

- Les items P0 sont bloquants pour les prochaines expÃ©rimentations
- Les items P1 amÃ©liorent le rÃ©alisme de la simulation
- Les items P2 sont des extensions futures
- Les items P3 sont des pistes de recherche Ã  long terme
- Note: `random_start=True` (dÃ©jÃ  implÃ©mentÃ©) est une forme de **Window Slicing** (data augmentation)

---

*DerniÃ¨re mise Ã  jour: 2026-01-19*
*Audit Observation Noise: 2026-01-19 - Voir `docs/AUDIT_OBSERVATION_NOISE.md`*
*Mise Ã  jour Short Selling + Funding Rate: 2026-01-19 - MarquÃ©s comme implÃ©mentÃ©s*
