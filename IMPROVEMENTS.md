# Am√©liorations Futures - CryptoRL

> **Instructions d'utilisation**
> 
> Ce fichier liste les am√©liorations pr√©vues pour le projet, organis√©es par priorit√©.
> 
> **Format des entr√©es :**
> - `[ ]` = √Ä faire
> - `[x]` = Impl√©ment√©
> - `[~]` = En cours
> - `[R]` = Rejet√©
> 
> **Priorit√©s :**
> - **P0** : BLOQUANT ‚õî - Invalide les r√©sultats, ne pas entra√Æner avant correction
> - **P1** : Haute priorit√© - Am√©liore significativement la qualit√©/robustesse
> - **P2** : Priorit√© moyenne - Am√©lioration incr√©mentale
> - **P3** : Basse priorit√© - Optimisations performance
> - **P4** : Recherche - Pistes √† long terme
> 
> **Mise √† jour :** Marquer les items comme `[x]` apr√®s impl√©mentation et ajouter la date.

---

## P0 - BLOQUANTS ‚õî (Invalident les r√©sultats)

> **‚ö†Ô∏è Ne lancer AUCUN entra√Ænement avant correction des P0.** Tout r√©sultat actuel est invalide.

### [x] Data Leakage - RobustScaler (fit sur tout dataset) ‚úÖ
**Fichier:** `src/data_engineering/manager.py:953`  
**Statut:** Impl√©ment√© (2026-01-22)  
**R√©f√©rence:** Audit Data Pipeline P0 - CONFIRM√â FATAL  
**Description:** Le `RobustScaler` fait un `.fit()` sur tout le dataset au lieu de train seulement. La m√©diane de t‚ÇÄ est influenc√©e par les prix de t‚Çä‚ÇÅ‚ÇÄ‚ÇÄ‚ÇÄ.  
**Fix:** Fit uniquement sur `train_set`, `transform` le `test_set` avec statistiques fig√©es du train.  
**Impact:** Test performance artificiellement gonfl√©e. L'agent "voit le futur".  
**Impl√©mentation:** Ajout du param√®tre `train_end_idx` dans `DataManager.pipeline()` pour fit sur train uniquement. Warning en mode legacy.

---

### [x] Data Leakage - Purge Window insuffisant (50h vs 720h) ‚úÖ
**Fichier:** `src/data_engineering/splitter.py:28`  
**Statut:** Impl√©ment√© (2026-01-22)  
**R√©f√©rence:** Audit Data Pipeline P0 - CONFIRM√â MATH√âMATIQUEMENT  
**Description:** Purge window de 50h est inf√©rieur √† la fen√™tre max des indicateurs (720h pour Z-Score). Les donn√©es entre T-720 et T-1 sont partag√©es entre train et validation.  
**Fix:** Augmenter √† 720h (max indicator window).  
**Impact:** Rolling features leak future info. D√©but du validation set pollu√© par fin du training set.  
**Impl√©mentation:** `DEFAULT_PURGE_WINDOW = 720` dans `constants.py`, utilis√© dans `splitter.py` et `run_full_wfo.py`. Validation ajout√©e pour garantir purge >= MAX_LOOKBACK_WINDOW.

---

### [x] Spectral Normalization (Stabilit√© Gradients) ‚úÖ
**Fichier:** `src/models/tqc_dropout_policy.py`  
**Statut:** Impl√©ment√© (2026-01-22)  
**R√©f√©rence:** Audit SOTA #1  
**Description:** Wrapper les couches `nn.Linear` du Critic avec `torch.nn.utils.spectral_norm` pour √©viter l'explosion des gradients en r√©gimes volatiles.  
**Impact:** Stabilit√© critique en HFT/Crypto volatile.  
**Impl√©mentation:** 
- Deux flags configurables: `use_spectral_norm_critic` et `use_spectral_norm_actor` (default: False)
- Appliqu√© uniquement aux couches cach√©es (pas la derni√®re couche output)
- Validation de compatibilit√© checkpoint ajout√©e dans `train_agent.py`
- ‚ö†Ô∏è **WARNING:** Checkpoints ne sont PAS compatibles si les flags `use_spectral_norm_*` changent entre entra√Ænements (incompatibilit√© `state_dict`)

---

### [x] Short Selling Support ‚úÖ
**Fichier:** `src/training/batch_env.py`  
**Statut:** Impl√©ment√© (2026-01-19)  
**Description:** Support complet du short selling avec mapping sym√©trique action=-1 ‚Üí -100% short.  
**Impact:** L'agent peut profiter des march√©s baissiers.

---

## P1 - Haute Priorit√© (Am√©liorations significatives)

### [ ] Tests Callbacks (test_callbacks.py)
**Fichier:** `tests/test_callbacks.py` (√† cr√©er)  
**R√©f√©rence:** Audit Mod√®les RL - CRITIQUE  
**Description:** Cr√©er tests pour `ThreePhaseCurriculumCallback` transitions et `OverfittingGuardV2` signal detection.  
**Impact:** Validation de la robustesse des callbacks critiques.

---

### [ ] Smooth Coef Tuning
**Fichier:** `src/training/callbacks.py`  
**Description:** Monitorer et ajuster la distribution de `w_cost` selon le nombre de trades par √©pisode.  
**Impact:** Balance entre r√©duction du churn et capacit√© √† trader via MORL.

---

### [ ] Rogers-Satchell Volatility (Robustesse)
**Fichier:** `src/data_engineering/features.py`  
**R√©f√©rence:** Audit Data Pipeline P2  
**Description:** Remplacer Garman-Klass par Rogers-Satchell (toujours >= 0, plus robuste). Garman-Klass peut produire des NaN.  
**Impact:** √âlimine les NaN dans les features de volatilit√©, plus robuste aux edge cases.

---

### [ ] Curriculum Lambda Max Tuning
**Fichier:** `src/training/batch_env.py`  
**Description:** Rendre `curriculum_lambda_max` configurable (actuellement hardcod√© √† 0.4).  
**Impact:** Permet de tuner le ratio PnL/Penalties selon les r√©sultats OOS.

---

### [ ] M√©triques Ensemble Avanc√©es (TensorBoard)
**Fichier:** `src/training/callbacks.py`  
**Description:** Logger les m√©triques ensemble (agreement, confidence, OOD score) dans TensorBoard pendant WFO.  
**Impact:** Visualisation de la sant√© de l'ensemble et d√©tection des r√©gimes OOD.

---

### [ ] Conservative Quantile Tuning (WFOConfig)
**Fichier:** `scripts/run_full_wfo.py`, `src/config/training.py`  
**Description:** Exposer `top_quantiles_to_drop_per_net` dans WFOConfig pour tuning selon profil (HFT vs Swing).  
**Impact:** Ajustement du conservatisme selon le timeframe sans modifier le code.

---

### [x] Embargo manquant (post-test gap) ‚úÖ
**Fichier:** `src/data_engineering/splitter.py`  
**Statut:** Impl√©ment√© (2026-01-22)  
**R√©f√©rence:** Audit Data Pipeline P1-NEW  
**Description:** Ajouter un gap apr√®s le test set pour √©viter contamination lors du retraining.  
**Impact:** Int√©grit√© des donn√©es pour retraining.  
**Impl√©mentation:** Param√®tre `embargo_window` ajout√© dans `TimeSeriesSplitter.split_data()` et `WFOConfig` (default 24h).

---

### [x] Training Multi-GPU Parall√®le (Ensemble) ‚úÖ
**Fichier:** `src/evaluation/ensemble.py`  
**Statut:** Impl√©ment√© (2026-01-22)  
**Description:** Training parall√®le des membres d'ensemble sur GPUs multiples via `torch.multiprocessing`.  
**Impact:** R√©duction du temps de training (3 membres ‚Üí 1/3 du temps avec 3 GPUs).

---

### [x] Funding Rate pour Shorts ‚úÖ
**Fichier:** `src/training/batch_env.py`  
**Statut:** Impl√©ment√© (2026-01-19)  
**Description:** Co√ªt de funding pour positions short (style perpetual futures).  
**Impact:** Short selling r√©aliste avec co√ªt de funding.

---

### [x] Funding Rate Synth√©tique D√©sactiv√© ‚úÖ
**Fichier:** `src/data_engineering/loader.py`  
**Statut:** Impl√©ment√© (2026-01-22)  
**R√©f√©rence:** Audit Data Pipeline P1.2  
**Description:** D√©sactiver le funding rate synth√©tique par d√©faut (causes spurious correlations). `HMM_Funding` retir√© de `HMM_FEATURES`.  
**Impact:** √âvite les corr√©lations fallacieuses, am√©liore la g√©n√©ralisation.  
**Impl√©mentation:** `use_synthetic_funding=False` par d√©faut, `HMM_Funding` retir√© de la liste des features HMM.

---

### [x] Retry Logic pour Download (Tenacity) ‚úÖ
**Fichier:** `src/data_engineering/loader.py`  
**Statut:** Impl√©ment√© (2026-01-22)  
**R√©f√©rence:** Audit Data Pipeline P1.3  
**Description:** Ajouter retry logic avec exponential backoff pour les t√©l√©chargements de donn√©es (r√©silience aux erreurs r√©seau).  
**Impact:** Robustesse face aux erreurs r√©seau temporaires.  
**Impl√©mentation:** D√©corateur `@retry` avec `tenacity` (3 tentatives, exponential backoff 4-10s).

---

### [x] Data Augmentation - Dynamic Noise ‚úÖ
**Fichier:** `src/training/batch_env.py`  
**Statut:** Impl√©ment√© (2026-01-19)  
**Description:** Bruit d'observation avec annealing temporel + adaptation √† la volatilit√©.  
**Impact:** Meilleure g√©n√©ralisation, convergence plus stable.

---

## P2 - Priorit√© Moyenne (Am√©liorations incr√©mentales)

### [x] WFO In-Train Evaluation ‚úÖ
**Fichier:** `scripts/run_full_wfo.py`  
**Statut:** Impl√©ment√© (2026-01-19)  
**Description:** Split "eval" entre train et test pour √©valuation in-train (EvalCallback) pendant WFO.  
**Impact:** D√©tection pr√©coce de l'overfitting, meilleure s√©lection de mod√®le.

---

### [ ] SharedMemory pour Replay Buffer (OOM Protection)
**Fichier:** `src/training/replay_buffer.py` (nouveau)  
**Description:** Utiliser `multiprocessing.SharedMemory` pour partager le Replay Buffer entre membres d'ensemble.  
**Impact:** R√©duit la m√©moire de O(n_members √ó buffer_size) √† O(buffer_size).

---

### [ ] Multi-Asset Support
**Fichier:** `src/training/batch_env.py`  
**Description:** √âtendre BatchCryptoEnv pour g√©rer un portefeuille multi-assets (BTC + ETH).  
**Impact:** Permet la diversification et les strat√©gies de spread.

---

### [ ] Stress Testing / Monte Carlo
**Fichier:** `src/evaluation/stress_testing.py` (nouveau)  
**Description:** √âvaluer la robustesse via simulation Monte Carlo et stress testing sur variations des donn√©es.  
**Impact:** √âvaluation robuste en conditions adverses, d√©tection d'overfitting.

---

### [ ] Data Augmentation - Magnitude Scaling
**Fichier:** `src/training/batch_env.py`  
**Description:** Multiplier les observations par un facteur al√©atoire pour simuler diff√©rentes conditions de volatilit√©.  
**Impact:** Simule diff√©rentes conditions de volatilit√©, pr√©serve la structure relative.

---

### [ ] Data Augmentation - Time Warping
**Fichier:** `src/training/batch_env.py`  
**Description:** √âtirer/compresser temporellement certaines portions de la s√©rie temporelle.  
**Impact:** Cr√©e de la vari√©t√© structurelle pour les patterns de chartisme.  
**Note:** Complexe √† impl√©menter, peut casser les relations temporelles.

---

### [x] A/B Testing: gSDE vs Actor Noise ‚úÖ
**Fichier:** `src/training/train_agent.py`, `src/config/training.py`  
**Statut:** Impl√©ment√© (2026-01-19)  
**Description:** Support pour deux approches d'exploration (gSDE et OrnsteinUhlenbeckActionNoise).  
**Impact:** Permet de tester quelle strat√©gie d'exploration fonctionne mieux.

---

## P3 - Basse Priorit√© / Optimisations

### [ ] Data Pipeline - FFD Vectoris√© (Performance 10x-100x)
**Fichier:** `src/data_engineering/features.py`  
**Description:** Impl√©menter FFD via FFT ou Numba JIT au lieu de boucle Python na√Øve.  
**Impact:** Pipeline de donn√©es 10x-100x plus rapide.

---

### [ ] Data Pipeline - Cache d_optimal Persistant
**Fichier:** `src/data_engineering/features.py`  
**Description:** Persister le cache `d_optimal` sur disque avec invalidation par hash des donn√©es.  
**Impact:** Skip ADF test si donn√©es inchang√©es (√©conomie ~30s par asset).

---

### [ ] Data Pipeline - Feature Computation Parall√®le
**Fichier:** `src/data_engineering/features.py`  
**Description:** Parall√©liser le calcul des features par asset avec `concurrent.futures`.  
**Impact:** Feature engineering 3-4x plus rapide sur machines multi-core.

---

## P4 - Recherche / Long Terme

### [ ] Chain of Inheritance pour Ensemble (Warm Start par Seed)
**Fichier:** `src/evaluation/ensemble.py`, `scripts/run_full_wfo.py`  
**Description:** Connecter les poids finaux de l'ensemble du segment N comme initialisation pour le segment N+1.  
**Impact:** Convergence plus rapide, continuit√© des repr√©sentations apprises.

---

### [ ] Ensemble RL v1.4 - Gaps Critiques SOTA
**Fichier:** `src/evaluation/ensemble.py`  
**Description:** 7 gaps identifi√©s pour passer de 8/10 √† 9+/10 : Composite Risk formel, BMA, Ensemble h√©t√©rog√®ne, Meta-contr√¥leur, VAE OOD, Transformers temporels.  
**R√©f√©rence:** `docs/design/ENSEMBLE_RL_DESIGN.md` v1.3 + Audit SOTA 2026-01-22  
**Impact:** Transformation vers framework bay√©sien, composite-risk, avec OOD structur√©.

---

### [ ] HMM Relative Artifacts + A/B Testing
**Fichier:** `src/data_engineering/features.py`  
**Description:** Passer √† des artifacts relatifs et impl√©menter A/B testing pour valider l'apport du HMM.  
**Impact:** Validation objective de l'apport du HMM.

---

### [ ] 3 HMM Timeframes
**Fichier:** `src/data_engineering/features.py`  
**Description:** Entra√Æner plusieurs HMM sur diff√©rents timeframes pour capturer les r√©gimes √† plusieurs √©chelles.  
**Impact:** Capture des r√©gimes de march√© √† court, moyen et long terme.

---

### [ ] Constrained RL Formalis√© (CMDP)
**Fichier:** Nouveau module  
**Description:** Formaliser les contraintes de trading via Constrained MDP avec Lagrangiens appris.  
**Impact:** Garanties th√©oriques sur le respect des contraintes, plus rigoureux que MORL heuristique.

---

### [ ] GP Diffusion Policy (GPDP)
**Fichier:** Nouveau module de recherche  
**Description:** R√©gularisation de la politique via Gaussian Process Regression.  
**R√©f√©rence:** "Overcoming Overfitting in RL via Gaussian Process Diffusion Policy" (arXiv:2506.13111)  
**Impact:** Potentiellement meilleure g√©n√©ralisation, mais effort de recherche significatif.

---

### [ ] Data Augmentation - Synthetic Episode Generation
**Fichier:** Nouveau module  
**Description:** G√©n√©rer des √©pisodes synth√©tiques avec mod√®les g√©n√©ratifs (GANs, Diffusion Models).  
**Impact:** Haute valeur si bien fait, mais effort tr√®s √©lev√©.

---

## üí° Insights / Best Practices

### Monitoring des Quantiles (Spread) - "Killer Feature" Anti-Overfitting

**Contexte:** D√©tection d'overfitting en Reinforcement Learning pour trading

**Probl√®me:** 
- En apprentissage supervis√©, on regarde la Loss Validation
- En RL, la "Reward OOS" est tr√®s bruit√©e et peu fiable pour d√©tecter l'overfitting

**Solution - Le Spread des Quantiles comme "Canari dans la Mine":**

Le **Spread des Quantiles** (√©cart entre quantiles min/max du Critic TQC) est un indicateur critique pour d√©tecter l'overfitting :

- **Signal d'overfitting:** Si le spread se r√©duit (le mod√®le devient s√ªr de lui) alors que la performance OOS stagne ou baisse, c'est la d√©finition exacte de l'overfitting (arrogance du mod√®le)
- **Signal de bonne g√©n√©ralisation:** Un spread stable ou qui augmente avec une performance OOS croissante indique une bonne g√©n√©ralisation

**Impl√©mentation recommand√©e:**
- Logger le spread des quantiles dans TensorBoard pendant l'entra√Ænement
- Monitorer la divergence entre spread (confiance du mod√®le) et performance OOS
- Alerter si spread ‚Üì + performance OOS ‚Üí ou ‚Üì (signe d'overfitting)

**R√©f√©rence:** Section 4.1 - Monitoring des Quantiles (Spread)

---

## Propositions REJET√âES

### [R] Feature-Specific Noise
**Raison:** Complexit√© de maintenance trop √©lev√©e pour gain marginal.  
**Alternative:** Reporter apr√®s validation des techniques approuv√©es.

---

### [R] SNI (Selective Noise Injection)
**Raison:** Changement architectural trop profond, hors scope.  
**Alternative:** Cr√©er ticket de recherche pour √©valuation future.

---

## Techniques √† √âVITER

| Technique | Pourquoi l'√©viter |
|-----------|-------------------|
| **Flip temporel** | Le temps a une direction. Un pattern invers√© temporellement devient compl√®tement diff√©rent. |
| **Shuffling des features** | Les colonnes ont une s√©mantique fixe. Le mod√®le apprend que colonne 0 = prix. |
| **Mixup/CutMix** | M√©langer deux contextes de march√© cr√©e une chim√®re irr√©aliste (mi-bull mi-bear). |
| **Bruit trop fort (>5%)** | D√©truit le signal. Le mod√®le apprend √† ignorer les observations. |

---

*Derni√®re mise √† jour: 2026-01-22*

---

## ‚úÖ Corrections Data Pipeline Compl√©t√©es (2026-01-22)

Toutes les corrections P0 et am√©liorations P1 du plan `data_pipeline_p0_fixes` ont √©t√© impl√©ment√©es :

- ‚úÖ **P0.1** - Fix scaler leakage (train_end_idx dans DataManager.pipeline)
- ‚úÖ **P0.2** - Fix purge window (50h ‚Üí 720h)
- ‚úÖ **P0.3** - Constantes centralis√©es (MAX_LOOKBACK_WINDOW, DEFAULT_PURGE_WINDOW, DEFAULT_EMBARGO_WINDOW)
- ‚úÖ **Tests** - test_data_leakage.py cr√©√© avec tests de non-fuite
- ‚úÖ **P1.1** - Embargo window ajout√©
- ‚úÖ **P1.2** - Funding rate synth√©tique d√©sactiv√©
- ‚úÖ **P1.3** - Retry logic avec tenacity

**R√©f√©rence:** `docs/audit/DATA_PIPELINE_AUDIT_REPORT.md` et plan `data_pipeline_p0_fixes_de0acb6b.plan.md`
