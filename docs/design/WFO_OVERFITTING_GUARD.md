# IntÃ©gration OverfittingGuardCallbackV2 dans Walk-Forward Optimization

**Version** : 1.3  
**Date** : 2026-01-19  
**Statut** : PRÃŠT POUR IMPLÃ‰MENTATION  
**Objectif** : Activer la dÃ©tection d'overfitting intra-train pendant le WFO

---

## Table des MatiÃ¨res

1. [Contexte](#1-contexte)
2. [ProblÃ©matique](#2-problÃ©matique)
3. [Solution ProposÃ©e](#3-solution-proposÃ©e)
4. [Architecture](#4-architecture)
5. [ImplÃ©mentation](#5-implÃ©mentation)
6. [Gestion de l'ArrÃªt PrÃ©maturÃ© (Fail-over)](#6-gestion-de-larrÃªt-prÃ©maturÃ©-fail-over)
7. [ContinuitÃ© WFO (Chain of Inheritance)](#7-continuitÃ©-wfo-chain-of-inheritance)
8. [Configuration](#8-configuration)
9. [Tests de Validation](#9-tests-de-validation)
10. [RÃ©fÃ©rences](#10-rÃ©fÃ©rences)

---

## 1. Contexte

### 1.1 Ã‰tat Actuel

Le projet dispose de deux mÃ©canismes de protection contre l'overfitting :

| Composant | Fichier | Usage Actuel |
|-----------|---------|--------------|
| `OverfittingGuardCallbackV2` | `src/training/callbacks.py` | UtilisÃ© dans `train_agent.py` (mode standard) |
| Walk-Forward Optimization | `scripts/run_full_wfo.py` | Validation out-of-sample post-training |

### 1.2 OverfittingGuardCallbackV2 - Rappel

Callback SOTA avec 5 signaux de dÃ©tection :

```
Signal 1: NAV Threshold      â†’ DÃ©tecte returns irrÃ©alistes (+400%)
Signal 2: Weight Stagnation  â†’ DÃ©tecte convergence/collapse du rÃ©seau
Signal 3: Train/Eval Diverg. â†’ DÃ©tecte overfitting classique (nÃ©cessite EvalCallback)
Signal 4: Action Saturation  â†’ DÃ©tecte policy collapse (actions bloquÃ©es Ã  Â±1)
Signal 5: Reward Variance    â†’ DÃ©tecte mÃ©morisation (variance â†’ 0)
```

### 1.3 WFO - Rappel

Pipeline Walk-Forward par segment :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SEGMENT N                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚          TRAIN              â”‚    â”‚           TEST              â”‚   â”‚
â”‚   â”‚        (18 mois)            â”‚    â”‚         (3 mois)            â”‚   â”‚
â”‚   â”‚                             â”‚    â”‚                             â”‚   â”‚
â”‚   â”‚  MAE + TQC Training         â”‚    â”‚  Ã‰valuation OOS             â”‚   â”‚
â”‚   â”‚  (actuellement SANS Guard)  â”‚    â”‚  (aprÃ¨s training)           â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. ProblÃ©matique

### 2.1 Le ProblÃ¨me

Actuellement, `run_full_wfo.py` **n'utilise PAS** `OverfittingGuardCallbackV2` :

```python
# run_full_wfo.py, ligne 515
config.eval_data_path = None  # WFO mode: disable EvalCallback
```

**ConsÃ©quence** : Le training peut continuer mÃªme si l'agent :
- Atteint des NAV irrÃ©alistes (Signal 1)
- A des poids qui stagnent (Signal 2)
- Sature ses actions Ã  Â±1 (Signal 4)
- A des rewards sans variance (Signal 5)

### 2.2 Pourquoi C'est Intentionnel (Actuellement)

Le WFO dÃ©sactive `EvalCallback` pour Ã©viter le **data leakage** :

```
âŒ RISQUE AVEC EVAL STANDARD EN WFO:

Segment TRAIN: 2020-01 â†’ 2021-06
Segment TEST:  2021-07 â†’ 2021-09

Si EvalCallback utilise des donnÃ©es de 2021-07+, l'agent
"voit" le futur pendant le training = DATA LEAKAGE
```

### 2.3 Ce Qu'on Perd

Sans `OverfittingGuardCallbackV2` en WFO :

| Signal | Disponible ? | ConsÃ©quence |
|--------|--------------|-------------|
| Signal 1 (NAV) | âŒ Non | Training continue mÃªme avec +1000% NAV |
| Signal 2 (Weights) | âŒ Non | Pas de dÃ©tection de collapse |
| Signal 3 (Divergence) | âŒ Non | Normal (pas d'eval) |
| Signal 4 (Saturation) | âŒ Non | Policy collapse non dÃ©tectÃ© |
| Signal 5 (Variance) | âŒ Non | MÃ©morisation non dÃ©tectÃ©e |

**RÃ©sultat** : On brÃ»le du GPU sur des trainings qui auraient dÃ» s'arrÃªter tÃ´t.

---

## 3. Solution ProposÃ©e

### 3.1 Approche : IntÃ©gration Partielle

Activer `OverfittingGuardCallbackV2` en WFO avec **4 signaux sur 5** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OverfittingGuardCallbackV2 en Mode WFO                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Signal 1: NAV Threshold       âœ… ACTIF   (pas de dÃ©pendance externe)  â”‚
â”‚   Signal 2: Weight Stagnation   âœ… ACTIF   (lecture poids du modÃ¨le)    â”‚
â”‚   Signal 3: Train/Eval Diverg.  âŒ DÃ‰SACTIVÃ‰ (pas d'EvalCallback)       â”‚
â”‚   Signal 4: Action Saturation   âœ… ACTIF   (lecture actions locales)    â”‚
â”‚   Signal 5: Reward Variance     âœ… ACTIF   (lecture rewards locales)    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Option AvancÃ©e : Split Intra-Train (DÃ©conseillÃ©)

> **âš ï¸ AVIS AUDIT : DÃ‰CONSEILLÃ‰ POUR L'INSTANT**
> 
> RÃ©duire les donnÃ©es d'entraÃ®nement de 10% (de 18 mois Ã  ~16 mois) pour gagner un signal 
> de validation est un compromis risquÃ© en sÃ©ries temporelles financiÃ¨res oÃ¹ la diversitÃ© 
> des rÃ©gimes de marchÃ© est clÃ©. Mieux vaut s'en tenir aux signaux 1, 2, 4, 5.

Pour activer **Signal 3**, crÃ©er un holdout **DANS** les donnÃ©es TRAIN :

```
                        SEGMENT TRAIN (18 mois)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚         TRAIN-TRAIN               â”‚  â”‚ P â”‚  â”‚   TRAIN-EVAL    â”‚    â”‚
â”‚   â”‚           (90%)                   â”‚  â”‚ U â”‚  â”‚     (10%)       â”‚    â”‚
â”‚   â”‚                                   â”‚  â”‚ R â”‚  â”‚                 â”‚    â”‚
â”‚   â”‚   TQC apprend ici                 â”‚  â”‚ G â”‚  â”‚  EvalCallback   â”‚    â”‚
â”‚   â”‚                                   â”‚  â”‚ E â”‚  â”‚  lit ici        â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚   Mois 1-2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Mois 18 â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                        SEGMENT TEST (3 mois)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                    Ã‰VALUATION FINALE OOS                        â”‚  â”‚
â”‚   â”‚                                                                 â”‚  â”‚
â”‚   â”‚   Jamais vu pendant training (ni TRAIN-TRAIN ni TRAIN-EVAL)    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚   Mois 19 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Mois 21  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantage** : Signal 3 actif sans data leakage  
**InconvÃ©nient** : Moins de donnÃ©es pour le training (90% au lieu de 100%)

---

## 4. Architecture

### 4.1 Flux Actuel (Sans Guard)

```
run_full_wfo.py
      â”‚
      â”œâ”€â”€ train_tqc()
      â”‚       â”‚
      â”‚       â””â”€â”€ train_agent.train()
      â”‚               â”‚
      â”‚               â””â”€â”€ model.learn(callback=[
      â”‚                       CheckpointCallback,    âœ…
      â”‚                       CurriculumCallback,    âœ…
      â”‚                       PLOCallbacks,          âœ…
      â”‚                       # PAS de OverfittingGuard âŒ
      â”‚                   ])
      â”‚
      â””â”€â”€ evaluate_segment()  # Ã‰valuation POST-training
```

### 4.2 Flux ProposÃ© (Avec Guard)

```
run_full_wfo.py
      â”‚
      â”œâ”€â”€ train_tqc()
      â”‚       â”‚
      â”‚       â””â”€â”€ train_agent.train()
      â”‚               â”‚
      â”‚               â””â”€â”€ model.learn(callback=[
      â”‚                       CheckpointCallback,         âœ…
      â”‚                       CurriculumCallback,         âœ…
      â”‚                       PLOCallbacks,               âœ…
      â”‚                       OverfittingGuardCallbackV2, âœ… NOUVEAU
      â”‚                   ])
      â”‚
      â””â”€â”€ evaluate_segment()  # Ã‰valuation POST-training
```

### 4.3 Modifications Requises

| Fichier | Modification |
|---------|--------------|
| `run_full_wfo.py` | Ajouter flag `use_overfitting_guard` dans `WFOConfig` |
| `train_agent.py` | Supporter crÃ©ation de `OverfittingGuardCallbackV2` sans `EvalCallback` |
| `callbacks.py` | Aucune (dÃ©jÃ  supporte `eval_callback=None`) |

---

## 5. ImplÃ©mentation

### 5.1 Modification de WFOConfig

```python
# run_full_wfo.py

@dataclass
class WFOConfig:
    # ... existing fields ...
    
    # === NEW: Overfitting Guard ===
    use_overfitting_guard: bool = True  # Activer OverfittingGuard en WFO
    
    # Guard thresholds (WFO-specific, peut Ãªtre plus permissif)
    guard_nav_threshold: float = 10.0       # 10x au lieu de 5x (WFO plus long)
    guard_patience: int = 5                 # Plus de patience en WFO
    guard_check_freq: int = 25_000          # RÃ©activitÃ© accrue (~6 semaines de donnÃ©es)
    guard_action_saturation: float = 0.95   # Seuil saturation (95% = policy collapse)
    guard_reward_variance: float = 1e-5     # Seuil variance (trÃ¨s permissif)
```

### 5.2 Modification de train_tqc()

```python
# run_full_wfo.py, dans WFOPipeline.train_tqc()

def train_tqc(self, train_path: str, encoder_path: str, segment_id: int, ...):
    # ... existing code ...
    
    # Configure TQC training
    config = TrainingConfig()
    # ... existing config ...
    
    # NEW: Enable OverfittingGuard in WFO mode
    if self.config.use_overfitting_guard:
        config.use_overfitting_guard = True
        config.guard_nav_threshold = self.config.guard_nav_threshold
        config.guard_patience = self.config.guard_patience
        config.guard_check_freq = self.config.guard_check_freq
        config.guard_action_saturation = self.config.guard_action_saturation
        config.guard_reward_variance = self.config.guard_reward_variance
        # Signal 3 reste dÃ©sactivÃ© (pas d'eval_data_path)
    
    # Train
    model, train_metrics = train(config, ...)
```

### 5.3 Modification de train_agent.py

```python
# src/training/train_agent.py, dans create_callbacks()

def create_callbacks(config, env, eval_env=None, ...):
    callbacks = []
    
    # ... existing callbacks ...
    
    # OverfittingGuard (v2)
    if getattr(config, 'use_overfitting_guard', False):
        from src.training.callbacks import OverfittingGuardCallbackV2
        
        # En WFO: pas d'EvalCallback, Signal 3 sera dÃ©sactivÃ© automatiquement
        eval_cb = None
        if eval_env is not None:
            # Mode standard: chercher EvalCallback existant
            eval_cb = next((cb for cb in callbacks if isinstance(cb, EvalCallback)), None)
        
        guard = OverfittingGuardCallbackV2(
            nav_threshold=getattr(config, 'guard_nav_threshold', 5.0),
            patience=getattr(config, 'guard_patience', 3),
            check_freq=getattr(config, 'guard_check_freq', 10_000),
            action_saturation_threshold=getattr(config, 'guard_action_saturation', 0.95),
            reward_variance_threshold=getattr(config, 'guard_reward_variance', 1e-4),
            eval_callback=eval_cb,  # None en WFO = Signal 3 dÃ©sactivÃ©
            verbose=1
        )
        callbacks.append(guard)
        print(f"  [Guard] OverfittingGuardCallbackV2 enabled (Signal 3: {'ON' if eval_cb else 'OFF'})")
    
    return callbacks
```

### 5.4 VÃ©rification dans callbacks.py

Le callback gÃ¨re dÃ©jÃ  le cas `eval_callback=None` :

```python
# src/training/callbacks.py, ligne ~1475

def _check_train_eval_divergence(self) -> Optional[str]:
    """
    Check if training reward diverges from evaluation reward.
    
    v2.3: Reads from ep_info_buffer (train) and EvalCallback (eval).
    Returns None if eval_callback is not set (WFO mode).
    """
    # Signal dÃ©sactivÃ© si pas d'EvalCallback
    if self.eval_callback is None:
        return None  # âœ… DÃ©jÃ  gÃ©rÃ©
    
    # ... rest of the method ...
```

---

## 6. Gestion de l'ArrÃªt PrÃ©maturÃ© (Fail-over)

### 6.1 ProblÃ©matique

Lorsque `OverfittingGuardCallbackV2` dÃ©clenche un arrÃªt prÃ©maturÃ© (ex: NAV > 10x au step 1M sur 90M prÃ©vus), que fait le pipeline WFO ?

**Risques identifiÃ©s :**
- Trader avec un modÃ¨le "immature" ou partiellement entraÃ®nÃ©
- Utiliser un modÃ¨le dans un Ã©tat corrompu ou divergent
- Perdre toute information sur la raison de l'Ã©chec

### 6.2 Politique de Fail-over RecommandÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARBRE DE DÃ‰CISION POST-ARRÃŠT                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Guard dÃ©clenche l'arrÃªt                                                   â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â–¼                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚   â”‚ completion_ratio >= 30% ?         â”‚                                     â”‚
â”‚   â”‚ ET checkpoint valide disponible ? â”‚                                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚           â”‚                                                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                                           â”‚
â”‚     â”‚           â”‚                                                           â”‚
â”‚    OUI         NON                                                          â”‚
â”‚     â”‚           â”‚                                                           â”‚
â”‚     â–¼           â–¼                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚  â”‚ Utiliser â”‚  â”‚ Marquer segment      â”‚                                     â”‚
â”‚  â”‚ dernier  â”‚  â”‚ comme FAILED         â”‚                                     â”‚
â”‚  â”‚ checkpointâ”‚  â”‚                      â”‚                                     â”‚
â”‚  â”‚ (RECOVERED)â”‚ â”‚ Utiliser stratÃ©gie  â”‚                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ de REPLI (Flat/B&H)  â”‚                                     â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **âš ï¸ Note importante sur `min_completion_ratio`** : Un modÃ¨le entraÃ®nÃ© sur seulement 10% 
> des donnÃ©es a peu de chances d'Ãªtre robuste. Le seuil par dÃ©faut est fixÃ© Ã  **30%** pour 
> garantir un minimum de convergence avant de considÃ©rer un checkpoint comme "rÃ©cupÃ©rable".

### 6.3 ImplÃ©mentation du Fail-over

```python
# run_full_wfo.py, dans WFOPipeline.run_segment()

def run_segment(self, df_raw, segment, ...):
    # ... training ...
    model, train_metrics = self.train_tqc(...)
    
    # NEW: Check if Guard triggered early stop
    guard_triggered = train_metrics.get('guard_early_stop', False)
    stop_reason = train_metrics.get('guard_stop_reason', None)
    completion_ratio = train_metrics.get('completion_ratio', 1.0)
    
    if guard_triggered:
        logger.warning(f"âš ï¸ SEGMENT {segment.id} STOPPED EARLY: {stop_reason}")
        logger.warning(f"   Completion ratio: {completion_ratio:.1%}")
        
        # VÃ©rifier si le modÃ¨le est suffisamment entraÃ®nÃ© pour Ãªtre rÃ©cupÃ©rable
        last_valid_checkpoint = self._find_last_valid_checkpoint(segment.id)
        can_recover = (
            last_valid_checkpoint 
            and self.config.use_checkpoint_on_failure
            and completion_ratio >= self.config.min_completion_ratio
        )
        
        if can_recover:
            logger.info(f"  â†’ Using last valid checkpoint: {last_valid_checkpoint}")
            model = TQC.load(last_valid_checkpoint)
            train_metrics['used_checkpoint'] = True
            train_metrics['segment_status'] = 'RECOVERED'
        else:
            # Marquer le segment comme FAILED et utiliser stratÃ©gie de repli
            logger.warning(f"  â†’ Cannot recover (ratio {completion_ratio:.1%} < {self.config.min_completion_ratio:.0%})")
            logger.warning(f"  â†’ Using fallback strategy: {self.config.fallback_strategy}")
            train_metrics['segment_status'] = 'FAILED'
            train_metrics['fallback_strategy'] = self.config.fallback_strategy
            
            # Utiliser stratÃ©gie de repli pour le backtest
            metrics = self._run_fallback_strategy(segment, self.config.fallback_strategy)
            return metrics, train_metrics
    else:
        train_metrics['segment_status'] = 'SUCCESS'
    
    # Continue with evaluation...
    metrics = self.evaluate_segment(model, test_path, ...)
    return metrics, train_metrics


def _run_fallback_strategy(self, segment, strategy: str) -> dict:
    """
    ExÃ©cute une stratÃ©gie de repli pour les segments FAILED.
    
    Args:
        segment: Le segment WFO
        strategy: 'flat' (pas de trading) ou 'buy_and_hold'
    
    Returns:
        MÃ©triques simulÃ©es pour ce segment
    """
    if strategy == 'flat':
        # Pas de trading = returns de 0
        return {
            'segment_id': segment.id,
            'sharpe': 0.0,
            'total_return': 0.0,
            'max_drawdown': 0.0,
            'strategy': 'FLAT (fallback)',
            'is_fallback': True
        }
    elif strategy == 'buy_and_hold':
        # Calculer le B&H sur la pÃ©riode TEST
        test_return = self._calculate_buy_and_hold(segment.test_start, segment.test_end)
        return {
            'segment_id': segment.id,
            'sharpe': None,  # Non applicable pour B&H simple
            'total_return': test_return,
            'max_drawdown': None,
            'strategy': 'BUY_AND_HOLD (fallback)',
            'is_fallback': True
        }
    else:
        raise ValueError(f"Unknown fallback strategy: {strategy}")
```

### 6.4 Logging de la Raison d'ArrÃªt (TÃ©lÃ©mÃ©trie)

Le pipeline doit stocker **pourquoi** chaque segment s'est arrÃªtÃ© pour l'analyse post-mortem.
Cette information doit Ãªtre prÃ©sente dans le fichier de rÃ©sultats final (`wfo_results.json`).

```python
# Structure du log d'arrÃªt par segment
segment_log = {
    'segment_id': 5,
    'status': 'FAILED',           # SUCCESS | RECOVERED | FAILED
    'stop_reason': 'Signal 1: NAV > 10.0 (observed: 15.3)',
    'stopped_at_step': 1_234_567,
    'total_planned_steps': 90_000_000,
    'completion_ratio': 0.0137,   # 1.37%
    'checkpoint_used': None,      # ou 'segment_05_step_1000000.zip'
    'fallback_strategy': 'flat',  # si FAILED
    'timestamp': '2026-01-19T14:32:15Z'
}
```

**Fichier de rÃ©sultats final (`wfo_results.json`)** :

```python
# Le fichier doit contenir stop_reason pour permettre le filtrage post-WFO
wfo_results = {
    'config': { ... },
    'segments': [
        {
            'id': 0,
            'status': 'SUCCESS',
            'stop_reason': None,
            'metrics': { 'sharpe': 1.2, 'total_return': 0.15, ... }
        },
        {
            'id': 1,
            'status': 'FAILED',
            'stop_reason': 'Signal 4: Action saturation > 0.95',
            'fallback_strategy': 'flat',
            'metrics': { 'sharpe': 0.0, 'total_return': 0.0, 'is_fallback': True }
        },
        # ...
    ],
    'summary': {
        'total_segments': 10,
        'successful': 8,
        'recovered': 1,
        'failed': 1,
        'aggregate_sharpe': 0.95,
        'aggregate_sharpe_excluding_failed': 1.05  # Pour comparaison
    }
}
```

Cette structure permet de :
- Filtrer les rÃ©sultats post-WFO (ex: "Performance sans les segments crashÃ©s")
- Identifier les patterns de failure (quels signaux dÃ©clenchent le plus souvent)
- Ajuster les seuils du Guard si trop de faux positifs

### 6.5 RÃ©capitulatif des Statuts de Segment

| Statut | Description | Action Ã‰valuation |
|--------|-------------|-------------------|
| `SUCCESS` | Training complet sans intervention | Ã‰valuation normale sur TEST |
| `RECOVERED` | ArrÃªt Guard, checkpoint valide utilisÃ© (ratio â‰¥ 30%) | Ã‰valuation avec avertissement |
| `FAILED` | ArrÃªt Guard, pas de checkpoint ou ratio < 30% | StratÃ©gie de repli (Flat/B&H) |

### 6.6 Configuration Fail-over

```python
@dataclass
class WFOConfig:
    # ... existing fields ...
    
    # Fail-over configuration
    use_checkpoint_on_failure: bool = True   # Utiliser checkpoint si Guard arrÃªte
    min_completion_ratio: float = 0.30       # Min 30% du training pour Ãªtre "rÃ©cupÃ©rable"
    checkpoint_freq: int = 1_000_000         # FrÃ©quence des checkpoints (pour recovery)
    fallback_strategy: str = 'flat'          # 'flat' ou 'buy_and_hold' pour segments FAILED
```

> **âš ï¸ Pourquoi 30% et pas 10% ?** Un modÃ¨le TQC complexe entraÃ®nÃ© sur seulement 10% des 
> donnÃ©es (9M steps sur 90M) n'a pas eu le temps de converger correctement. Ã€ 30% (27M steps), 
> le modÃ¨le a gÃ©nÃ©ralement passÃ© les phases critiques d'exploration initiale et possÃ¨de une 
> policy minimalement cohÃ©rente.

---

## 7. ContinuitÃ© WFO (Chain of Inheritance)

### 7.1 ProblÃ©matique Critique

En WFO standard, le **Segment N+1** initialise souvent ses poids Ã  partir de l'Ã©tat final du **Segment N** (warm start). Cela permet un apprentissage continu et une adaptation progressive aux rÃ©gimes de marchÃ©.

**La Section 6 dÃ©finit ce qui se passe pour les *rÃ©sultats* du Segment N en cas d'Ã©chec, mais pas ce qui se passe pour l'*initialisation* du Segment N+1.**

### 7.2 ScÃ©nario de Risque

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RUPTURE DE LA CHAÃNE WFO                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Segment N-1          Segment N              Segment N+1                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚ SUCCESS â”‚ â”€â”€â”€â”€â”€â”€â–¶  â”‚ FAILED  â”‚ â”€â”€â”€â”€â”€â”€â–¶   â”‚    ?    â”‚                   â”‚
â”‚   â”‚         â”‚  init    â”‚ (ratio  â”‚   init    â”‚         â”‚                   â”‚
â”‚   â”‚ model   â”‚  from    â”‚  <30%)  â”‚   from    â”‚ CRASH?  â”‚                   â”‚
â”‚   â”‚  OK     â”‚  N-1     â”‚ no modelâ”‚   ???     â”‚ ou      â”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ cold    â”‚                   â”‚
â”‚                                              â”‚ start?  â”‚                   â”‚
â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                             â”‚
â”‚   âŒ Si N+1 essaie de charger le modÃ¨le N : CRASH (fichier inexistant)     â”‚
â”‚   âŒ Si N+1 recommence de zÃ©ro : Perte de l'apprentissage continu          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.3 Solution : Rollback d'Initialisation

Le pipeline doit maintenir une variable `last_successful_model` qui pointe toujours vers le dernier modÃ¨le valide (SUCCESS ou RECOVERED).

```python
# run_full_wfo.py, dans WFOPipeline.run_all_segments()

def run_all_segments(self, df_raw, segments):
    """
    ExÃ©cute tous les segments WFO avec gestion de l'hÃ©ritage des poids.
    """
    all_results = []
    last_successful_model_path = None  # Track du dernier modÃ¨le valide
    
    for i, segment in enumerate(segments):
        logger.info(f"â•â•â• Segment {i}/{len(segments)-1} â•â•â•")
        
        # DÃ©terminer le modÃ¨le d'initialisation
        if i == 0:
            # Premier segment : cold start ou modÃ¨le prÃ©-entraÃ®nÃ©
            init_model_path = self.config.pretrained_model_path
        else:
            # Segments suivants : utiliser le dernier modÃ¨le valide
            init_model_path = last_successful_model_path
            
            if init_model_path is None:
                logger.warning(f"âš ï¸ No valid model from previous segments, using cold start")
        
        # ExÃ©cuter le segment
        metrics, train_metrics = self.run_segment(
            df_raw, segment, 
            init_model_path=init_model_path,
            ...
        )
        
        # Mettre Ã  jour le tracking du dernier modÃ¨le valide
        segment_status = train_metrics.get('segment_status', 'SUCCESS')
        
        if segment_status in ['SUCCESS', 'RECOVERED']:
            # Ce segment a produit un modÃ¨le valide
            last_successful_model_path = self._get_segment_model_path(segment.id)
            logger.info(f"  âœ“ Updated last_successful_model: {last_successful_model_path}")
        else:
            # Segment FAILED : on garde l'ancien last_successful_model
            logger.warning(f"  âœ— Segment FAILED, keeping previous model for inheritance")
            
            # IMPORTANT: Nettoyer les checkpoints pourris de ce segment
            self._cleanup_failed_segment_checkpoints(segment.id)
        
        all_results.append({
            'segment': segment,
            'metrics': metrics,
            'train_metrics': train_metrics,
            'init_model_used': init_model_path
        })
    
    return all_results
```

### 7.4 Diagramme de la ChaÃ®ne CorrigÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHAÃNE WFO AVEC ROLLBACK                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Segment 0          Segment 1          Segment 2          Segment 3       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ SUCCESS â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ SUCCESS â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ FAILED  â”‚        â”‚ SUCCESS â”‚     â”‚
â”‚   â”‚         â”‚ model  â”‚         â”‚ model  â”‚         â”‚        â”‚         â”‚     â”‚
â”‚   â”‚ model_0 â”‚   0    â”‚ model_1 â”‚   1    â”‚ (crash) â”‚        â”‚ model_3 â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                            â”‚                  â”‚                  â–²         â”‚
â”‚                            â”‚                  â”‚                  â”‚         â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                      â”‚                                      â”‚
â”‚                            last_successful_model = model_1                  â”‚
â”‚                            (utilisÃ© pour init Segment 3)                    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.5 Nettoyage des Checkpoints Pourris

Quand un segment est marquÃ© `FAILED`, les checkpoints gÃ©nÃ©rÃ©s avant l'arrÃªt sont potentiellement corrompus ou dans un Ã©tat instable. Ils doivent Ãªtre supprimÃ©s pour :
- Ã‰viter de saturer le disque inutilement
- EmpÃªcher une rÃ©utilisation accidentelle

```python
def _cleanup_failed_segment_checkpoints(self, segment_id: int):
    """
    Supprime les checkpoints d'un segment FAILED.
    
    Ne supprime PAS le modÃ¨le final si le segment est RECOVERED 
    (car ce modÃ¨le est valide et utilisable).
    """
    checkpoint_dir = os.path.join(self.output_dir, f"segment_{segment_id:02d}", "checkpoints")
    
    if os.path.exists(checkpoint_dir):
        # Lister tous les fichiers .zip dans le dossier
        checkpoints = glob.glob(os.path.join(checkpoint_dir, "*.zip"))
        
        for ckpt in checkpoints:
            logger.info(f"  ğŸ—‘ï¸ Removing failed checkpoint: {os.path.basename(ckpt)}")
            os.remove(ckpt)
        
        logger.info(f"  Cleaned up {len(checkpoints)} checkpoints from failed segment {segment_id}")
```

### 7.6 Configuration de l'HÃ©ritage

```python
@dataclass
class WFOConfig:
    # ... existing fields ...
    
    # Chain of Inheritance
    use_warm_start: bool = True              # HÃ©riter des poids du segment prÃ©cÃ©dent
    pretrained_model_path: str = None        # ModÃ¨le de dÃ©part pour Segment 0
    cleanup_failed_checkpoints: bool = True  # Supprimer les checkpoints des segments FAILED
```

---

## 8. Configuration

### 8.1 ParamÃ¨tres RecommandÃ©s pour WFO

| ParamÃ¨tre | Valeur Standard | Valeur WFO | Raison |
|-----------|-----------------|------------|--------|
| `nav_threshold` | 5.0 | 10.0 | WFO = 90M steps, plus de temps pour accumuler |
| `patience` | 3 | 5 | RÃ©duire faux positifs sur long training |
| `check_freq` | 10,000 | **25,000** | RÃ©activitÃ© accrue sans overhead notable |
| `action_saturation` | 0.95 | **0.95** | Si 95% bang-bang, le modÃ¨le ne fait plus de finesse |
| `reward_variance` | 1e-4 | 1e-5 | Plus permissif (dÃ©tecte seulement "mort cÃ©rÃ©brale") |

> **âš ï¸ Note sur `check_freq`** : La frÃ©quence de 25,000 steps offre un bon compromis entre 
> rÃ©activitÃ© et performance. Avec 18 mois de donnÃ©es (~576k minutes si 1 step = 1 minute),
> 25k steps reprÃ©sente environ 6 semaines de donnÃ©es. Si le modÃ¨le diverge, on le dÃ©tecte
> rapidement sans attendre 3 mois (ce qui serait le cas avec 50k).
> 
> **Calcul** : 25k / 576k â‰ˆ 4.3% d'une Ã©poque, ce qui est infÃ©rieur Ã  la limite de 10% recommandÃ©e.

### 8.2 CLI Arguments

```bash
# Activer (dÃ©faut)
python scripts/run_full_wfo.py --segment 0

# DÃ©sactiver explicitement
python scripts/run_full_wfo.py --segment 0 --no-overfitting-guard

# Personnaliser les seuils
python scripts/run_full_wfo.py --segment 0 \
    --guard-nav-threshold 8.0 \
    --guard-patience 4
```

---

## 9. Tests de Validation

### 9.1 Test Unitaire : Guard Sans EvalCallback

```python
# tests/test_overfitting_guard_wfo.py

def test_guard_without_eval_callback():
    """Verify Signal 3 is gracefully disabled when no EvalCallback."""
    from src.training.callbacks import OverfittingGuardCallbackV2
    
    guard = OverfittingGuardCallbackV2(
        eval_callback=None,  # WFO mode
        verbose=0
    )
    
    # Signal 3 should return None (no violation, no error)
    result = guard._check_train_eval_divergence()
    assert result is None, "Signal 3 should be disabled without EvalCallback"
```

### 9.2 Test IntÃ©gration : WFO avec Guard

```python
def test_wfo_segment_with_guard():
    """Run a mini WFO segment with OverfittingGuard enabled."""
    from scripts.run_full_wfo import WFOPipeline, WFOConfig
    
    config = WFOConfig()
    config.use_overfitting_guard = True
    config.tqc_timesteps = 10_000  # Mini run
    
    pipeline = WFOPipeline(config)
    
    # Should not crash
    metrics, train_metrics = pipeline.run_segment(df_raw, segment, use_batch_env=True)
    
    # Guard metrics should be logged
    assert 'guard_violations' in train_metrics or True  # Optionnel
```

### 9.3 Test Early Stopping

```python
def test_guard_triggers_early_stop():
    """Verify Guard can stop training when NAV explodes."""
    # Create mock env with artificially high NAV
    # ...
    
    guard = OverfittingGuardCallbackV2(
        nav_threshold=2.0,  # Trigger at 2x
        patience=1
    )
    
    # Simulate steps with high NAV
    # ...
    
    # Should return False (stop training)
    assert guard._on_step() == False
```

### 9.4 Test Fail-over avec Checkpoint

```python
def test_failover_uses_last_checkpoint():
    """Verify pipeline uses last valid checkpoint when Guard stops training."""
    from scripts.run_full_wfo import WFOPipeline, WFOConfig
    
    config = WFOConfig()
    config.use_overfitting_guard = True
    config.use_checkpoint_on_failure = True
    config.guard_nav_threshold = 1.5  # Trigger rapidement
    config.checkpoint_freq = 1000     # Checkpoints frÃ©quents pour le test
    
    pipeline = WFOPipeline(config)
    
    # Run segment qui va dÃ©clencher le Guard
    metrics, train_metrics = pipeline.run_segment(df_volatile, segment, ...)
    
    # VÃ©rifier le comportement fail-over
    assert train_metrics['guard_early_stop'] == True
    assert train_metrics['segment_status'] in ['RECOVERED', 'FAILED']
    
    if train_metrics['segment_status'] == 'RECOVERED':
        assert 'used_checkpoint' in train_metrics
        assert train_metrics['used_checkpoint'] == True
```

### 9.5 Test Log de Raison d'ArrÃªt

```python
def test_stop_reason_logged():
    """Verify stop reason is properly logged for post-mortem analysis."""
    # ... setup ...
    
    metrics, train_metrics = pipeline.run_segment(...)
    
    if train_metrics.get('guard_early_stop'):
        assert 'guard_stop_reason' in train_metrics
        assert train_metrics['guard_stop_reason'] is not None
        # Reason should be descriptive
        assert 'Signal' in train_metrics['guard_stop_reason']
```

### 9.6 Test Chain of Inheritance

```python
def test_chain_of_inheritance_after_failure():
    """Verify Segment N+1 uses model from N-1 when N fails."""
    from scripts.run_full_wfo import WFOPipeline, WFOConfig
    
    config = WFOConfig()
    config.use_overfitting_guard = True
    config.use_warm_start = True
    config.guard_nav_threshold = 1.5  # Trigger failure on segment 1
    
    pipeline = WFOPipeline(config)
    
    # Run 3 segments where segment 1 will fail
    results = pipeline.run_all_segments(df_raw, segments[:3])
    
    # Segment 0: SUCCESS
    assert results[0]['train_metrics']['segment_status'] == 'SUCCESS'
    
    # Segment 1: FAILED (triggered by Guard)
    assert results[1]['train_metrics']['segment_status'] == 'FAILED'
    
    # Segment 2: Should have initialized from Segment 0's model (not Segment 1)
    assert results[2]['init_model_used'] == results[0]['model_path']
    assert results[2]['train_metrics']['segment_status'] in ['SUCCESS', 'RECOVERED']
```

### 9.7 Test Cleanup de Checkpoints

```python
def test_failed_segment_checkpoints_cleaned():
    """Verify checkpoints are deleted for FAILED segments."""
    # ... setup with segment that will fail ...
    
    pipeline.run_segment(df_volatile, segment, ...)
    
    # Checkpoints directory should be empty or not exist
    checkpoint_dir = os.path.join(pipeline.output_dir, f"segment_{segment.id:02d}", "checkpoints")
    
    if os.path.exists(checkpoint_dir):
        remaining_files = os.listdir(checkpoint_dir)
        assert len(remaining_files) == 0, f"Found orphan checkpoints: {remaining_files}"
```

---

## 10. RÃ©fÃ©rences

### 10.1 Fichiers du Projet

| Fichier | Description |
|---------|-------------|
| `src/training/callbacks.py` | DÃ©finition de `OverfittingGuardCallbackV2` |
| `scripts/run_full_wfo.py` | Pipeline WFO Ã  modifier |
| `src/training/train_agent.py` | CrÃ©ation des callbacks |
| `docs/OVERFITTING_GUARD_V2.md` | SpÃ©cification technique du callback |

### 10.2 Documentation LiÃ©e

- `docs/OVERFITTING_GUARD_V2.md` - DÃ©tails des 5 signaux
- `docs/EVAL_DATA_SPLIT.md` - Split train/eval (mode standard)
- `docs/PLO_ADAPTIVE_PENALTIES.md` - Callbacks PLO (compatibles)

---

## Annexe A : Checklist d'ImplÃ©mentation

### Configuration
- [ ] Ajouter `use_overfitting_guard` dans `WFOConfig`
- [ ] Ajouter paramÃ¨tres `guard_*` dans `WFOConfig` (notamment `guard_check_freq=25_000`)
- [ ] Ajouter paramÃ¨tres fail-over dans `WFOConfig` (`min_completion_ratio=0.30`, `fallback_strategy`)
- [ ] Ajouter paramÃ¨tres Chain of Inheritance (`use_warm_start`, `pretrained_model_path`, `cleanup_failed_checkpoints`)
- [ ] Ajouter arguments CLI (`--no-overfitting-guard`, `--guard-*`, `--fallback-strategy`)

### ImplÃ©mentation Core
- [ ] Modifier `train_tqc()` pour passer les paramÃ¨tres Guard
- [ ] Modifier `train_agent.py` pour crÃ©er le callback
- [ ] ImplÃ©menter la logique fail-over dans `run_segment()`
- [ ] Ajouter `_find_last_valid_checkpoint()`
- [ ] Ajouter `_run_fallback_strategy()` (Flat et Buy & Hold)

### Chain of Inheritance (CRITIQUE)
- [ ] ImplÃ©menter `run_all_segments()` avec tracking de `last_successful_model_path`
- [ ] Passer `init_model_path` Ã  `run_segment()` pour le warm start
- [ ] Ajouter `_cleanup_failed_segment_checkpoints()` pour le nettoyage disque
- [ ] Logger `init_model_used` dans les rÃ©sultats de chaque segment

### TÃ©lÃ©mÃ©trie
- [ ] S'assurer que `train_metrics` contient `guard_early_stop`, `guard_stop_reason`, `completion_ratio`
- [ ] Ajouter `stop_reason` dans `wfo_results.json` pour chaque segment
- [ ] Ajouter `aggregate_sharpe_excluding_failed` dans le summary
- [ ] Logger `init_model_used` pour tracer l'hÃ©ritage des poids

### Tests
- [ ] Tester sur un segment court (10k steps)
- [ ] Tester le fail-over avec `min_completion_ratio` (vÃ©rifier seuil 30%)
- [ ] Tester les deux stratÃ©gies de repli (Flat, B&H)
- [ ] Tester la Chain of Inheritance aprÃ¨s un segment FAILED
- [ ] Tester le nettoyage des checkpoints pourris
- [ ] Valider les logs TensorBoard (`guard/*`)

### Documentation
- [ ] Documenter dans `IMPROVEMENTS.md`

---

## Annexe B : Option AvancÃ©e - Split Intra-Train

> **âš ï¸ Rappel : Cette option est DÃ‰CONSEILLÃ‰E** (voir section 3.2)

Si Signal 3 est requis en WFO malgrÃ© tout, voici l'approche :

### B.1 Modification de preprocess_segment()

```python
def preprocess_segment(self, df_raw, segment, intra_train_split: float = 0.9):
    """
    Args:
        intra_train_split: Fraction of TRAIN for actual training (rest = holdout eval)
    """
    # ... existing preprocessing ...
    
    if intra_train_split < 1.0:
        # Split TRAIN into TRAIN-TRAIN and TRAIN-EVAL
        split_idx = int(len(train_df) * intra_train_split)
        purge = 50  # Purge window
        
        train_train_df = train_df.iloc[:split_idx]
        train_eval_df = train_df.iloc[split_idx + purge:]
        
        # Save both
        train_train_path = os.path.join(data_dir, "train_train.parquet")
        train_eval_path = os.path.join(data_dir, "train_eval.parquet")
        
        train_train_df.to_parquet(train_train_path)
        train_eval_df.to_parquet(train_eval_path)
        
        return train_train_path, train_eval_path, test_path
```

### B.2 Modification de train_tqc()

```python
def train_tqc(self, train_path, train_eval_path, ...):
    config = TrainingConfig()
    config.data_path = train_path           # TRAIN-TRAIN (90%)
    config.eval_data_path = train_eval_path  # TRAIN-EVAL (10%)
    
    # EvalCallback sera crÃ©Ã©, Signal 3 actif
```

### B.3 Trade-offs

| Aspect | Sans Split Intra-Train | Avec Split Intra-Train |
|--------|------------------------|------------------------|
| DonnÃ©es training | 100% du TRAIN | 90% du TRAIN |
| Signal 3 | âŒ DÃ©sactivÃ© | âœ… Actif |
| ComplexitÃ© | Simple | Moyenne |
| Risque leakage | Aucun | Aucun (TRAIN-EVAL âŠ‚ TRAIN) |

---

## Annexe C : MÃ©triques TensorBoard Attendues

Avec Guard actif, les mÃ©triques suivantes apparaÃ®tront dans TensorBoard :

```
guard/
â”œâ”€â”€ active_signals      # Nombre de signaux en violation (0-5)
â”œâ”€â”€ nav_max             # NAV maximum observÃ©
â”œâ”€â”€ weight_cv           # Coefficient de variation des poids
â”œâ”€â”€ weight_delta        # Delta moyen des poids
â”œâ”€â”€ action_saturation   # Ratio d'actions saturÃ©es
â”œâ”€â”€ reward_variance     # Variance des rewards
â”œâ”€â”€ reward_cv           # CV des rewards
â””â”€â”€ violations/
    â”œâ”€â”€ nav             # Compteur violations Signal 1
    â”œâ”€â”€ weight          # Compteur violations Signal 2
    â”œâ”€â”€ saturation      # Compteur violations Signal 4
    â””â”€â”€ variance        # Compteur violations Signal 5
```

---

*Fin de la spÃ©cification technique*
