# CONTEXTE PROJET - CryptoRL

> **Projet:** Reinforcement Learning pour trading de cryptomonnaies
> **DerniÃ¨re mise Ã  jour:** 2026-01-26

---

## ğŸš¨ ProblÃ¨me actuel: Policy Collapse

### SymptÃ´mes
- **Actions fixes:** Le TQC converge vers une position constante (ex: +85% LONG ou -1.4% SHORT)
- **Action Entropy = 0:** Aucune exploration
- **Feature Attribution â‰ˆ 0:** Le modÃ¨le ignore les inputs (amÃ©lioration rÃ©cente: attribution > 0)

### Historique des audits

| Date | Steps | Position | Attribution | Sharpe | Status |
|------|-------|----------|-------------|--------|--------|
| 25/01 | 30M | +85% LONG | 0 | +1.15 | âŒ Collapse |
| 26/01 | 1M | +4% neutre | 0 | +1.10 | âŒ Collapse |
| 26/01 | 25M | -1.4% SHORT | **>0** | -2.68 | âš ï¸ Attribution OK, collapse |

### Corrections appliquÃ©es
1. **ent_coef:** `auto_0.1` â†’ `auto_0.5` (target entropy plus Ã©levÃ©)
2. **EntropyFloorCallback:** `min_ent_coef=0.01` (empÃªche collapse total)
3. **Commit:** `56fee93`, `3c36fbc`

### Diagnostic gSDE
```
log_std mean: -0.039 â†’ std â‰ˆ 0.96 âœ…
Actions std (stochastique): 0.798 âœ…
Actions range: [-0.999, +0.999] âœ…
```
Le gSDE fonctionne, mais la policy converge vers une action fixe.

---

## ğŸ—ï¸ Architecture (Split Input + FiLM)

```
Observation Dict:
â”œâ”€â”€ market: (B, 64, 55)     # 50 Tech + 5 HMM
â”œâ”€â”€ position: (B, 1)
â””â”€â”€ w_cost: (B, 1)

FoundationFeatureExtractor:
â”œâ”€â”€ Split Input:
â”‚   â”œâ”€â”€ Tech Features (cols 0-49) â†’ MAE Encoder (frozen, d_model=256)
â”‚   â””â”€â”€ HMM Context (cols 50-54) â†’ FiLM modulation
â”œâ”€â”€ FiLM: Î³, Î² from HMM context modulate MAE embeddings
â”œâ”€â”€ Flatten: (B, 64, 256) â†’ (B, 16384)
â”œâ”€â”€ Concat: [market_flat, position, w_cost] â†’ (B, 16386)
â””â”€â”€ Fusion Projector: Linear(16386 â†’ 512) + LayerNorm + LeakyReLU
```

### Dimensions MAE (constants.py)
```python
MAE_D_MODEL = 256      # DOIT correspondre au checkpoint
MAE_N_HEADS = 4
MAE_N_LAYERS = 2
MAE_DIM_FEEDFORWARD = 1024  # 4 * d_model
```

### Validation (validators.py)
- `ModelDimensionsValidator`: DÃ©tecte les mismatches d_model/n_heads/input_dim
- Erreur claire si checkpoint incompatible avec config

---

## ğŸ“ Structure du projet

```
cryptoRL/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ wfo/segment_X/         # DonnÃ©es WFO (train/eval/test.parquet)
â”‚   â””â”€â”€ raw_historical/        # DonnÃ©es historiques OHLCV
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ wfo/segment_X/         # TensorBoard logs
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ wfo/segment_X/         # Checkpoints (encoder.pth, tqc.zip)
â”œâ”€â”€ results/
â”‚   â””â”€â”€ tqc_audit/             # Rapports d'audit
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_full_wfo.py        # Pipeline WFO principal
â”‚   â””â”€â”€ audit_pipeline.py      # Audits (HMM, MAE, TQC, FiLM)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ constants.py       # MAE dimensions, HMM_CONTEXT_SIZE
â”‚   â”‚   â”œâ”€â”€ training.py        # TQCTrainingConfig, WFOTrainingConfig
â”‚   â”‚   â””â”€â”€ validators.py      # ModelDimensionsValidator
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ foundation.py      # CryptoMAE
â”‚   â”‚   â”œâ”€â”€ rl_adapter.py      # FoundationFeatureExtractor + FiLM
â”‚   â”‚   â””â”€â”€ layers.py          # FiLMLayer
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ train_agent.py     # EntraÃ®nement TQC
â”‚       â”œâ”€â”€ batch_env.py       # BatchCryptoEnv (GPU)
â”‚       â””â”€â”€ callbacks.py       # EntropyFloorCallback, etc.
â””â”€â”€ tests/
    â”œâ”€â”€ test_film_extractor.py # Tests FiLM
    â””â”€â”€ test_hmm_features.py   # Tests HMM (look-ahead bias)
```

---

## âš™ï¸ Configuration actuelle

### WFO Training (WFOTrainingConfig)
| ParamÃ¨tre | Valeur |
|-----------|--------|
| timesteps | 25,000,000 |
| n_envs | 1024 |
| batch_size | 512 |
| learning_rate | 3e-4 â†’ decay |
| gamma | 0.95 |
| ent_coef | `auto_0.5` |
| sde_sample_freq | 64 |
| log_std_init | 0.0 (Shock Therapy) |

### Reward (batch_env.py)
```
Mean:   -0.033
Std:    0.059
Range:  [-0.39, +0.24]
```

### Callbacks
- `EntropyFloorCallback`: min_ent_coef=0.01
- `MORLCurriculumCallback`: w_cost curriculum
- `RotatingCheckpointCallback`: Optimisation disque
- `UnifiedMetricsCallback`: TensorBoard logging

---

## ğŸ–¥ï¸ Serveur distant

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| Host | `172.219.157.164` |
| Port | `21130` |
| User | `root` |
| Provider | vast.ai |

**Connexion:**
```bash
ssh -p 21130 root@172.219.157.164

# Tunnel TensorBoard
ssh -p 21130 -L 8081:localhost:8081 root@172.219.157.164
```

**Script init serveur:** `scripts/init_server.ps1`

---

## ğŸ”§ Commandes utiles

### WFO
```bash
# Clean + Launch
python scripts/run_full_wfo.py --clean
python scripts/run_full_wfo.py --segment 0 --timesteps 25000000

# Sur serveur (background)
nohup python3 scripts/run_full_wfo.py --segment 0 --timesteps 25000000 </dev/null >logs/wfo_segment0.log 2>&1 &
```

### Audit TQC
```bash
python -m scripts.audit_pipeline --mode tqc --tqc-segment 0
```

### Tests
```bash
pytest tests/ -v
python -m scripts.test_film_extractor  # Test FiLM
```

---

## ğŸ“Š Tests de diagnostic

### Test gSDE (exploration)
```python
# Sur serveur
python3 -c "
import torch
from sb3_contrib import TQC
model = TQC.load('weights/wfo/segment_0/tqc.zip')
actor = model.policy.actor
print(f'log_std mean: {actor.log_std.mean().item():.4f}')
print(f'std mean: {torch.exp(actor.log_std).mean().item():.4f}')
"
```

### Test Feature Extractor
```python
# VÃ©rifie que MAE, FiLM, position, w_cost fonctionnent
python -m tests.test_film_extractor
```

### Test Reward Amplitude
```python
# Voir amplitude des rewards aprÃ¨s normalisation
python3 -c "
from src.training.batch_env import BatchCryptoEnv
env = BatchCryptoEnv('data/wfo/segment_0/train.parquet', ...)
# Collecter rewards et afficher stats
"
```

---

## ğŸ¯ Prochaines Ã©tapes

1. **Investiguer policy collapse** malgrÃ© attribution > 0
2. **VÃ©rifier critic loss** - Q-values plates?
3. **Tester reward scaling** - amplitude trop faible?
4. **Explorer target_entropy** - valeur optimale?

---

*Document mis Ã  jour aprÃ¨s audits TQC du 26/01/2026*
